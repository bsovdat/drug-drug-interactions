{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf9jcAcuERdu"
      },
      "source": [
        "# Predicting drug-drug interactions with GraphSAGE + JK-Net\n",
        "\n",
        "*A final project by Bla≈æ Erzar, Bernard Sovdat, and Klemen Vovk for the Stanford [CS224W class](https://web.stanford.edu/class/cs224w/) in the Fall of 2021.*\n",
        "\n",
        "Graph neural networks are often thought of as hard and challenging subject. Our goal in this colab is to explain and show a real world use case of GNNs.\n",
        "\n",
        "We are assuming the readers are familiar with machine learning and deep learning concepts and a working knowledge of Pytorch is required to understand the programming examples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7t5rUIXEjJS"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "If you take several different medicines, see more than one doctor, or have certain health conditions, you and your doctors need to be aware of all the medicines you take. Doing so will help you to avoid potential problems such as drug interactions.\n",
        "\n",
        "Drugs interacting in your body might make your drug less effective, increase the action of a particular drug, or cause unexpected side effects. Some drug interactions could even be harmful to the patient.\n",
        "\n",
        "Drug interactions can be dangerous although side effects might seem harmless. For example, mixing a drug you take to help you sleep (a sedative) and a drug you take for allergies (an antihistamine) can slow your reactions and make driving a car or operating machinery dangerous.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP41Dzy8ErYE"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Starting knowledge is given with the **ogbl-ddi** dataset from Open Graph Benchmark, which is a  collection of realistic, large-scale, and diverse benchmark datasets for machine learning on graphs.\n",
        "\n",
        "This dataset is a homogeneous, unweighted, undirected graph, representing the drug-drug interaction network. Each node represents an FDA-approved or experimental drug. Edges represent interactions between drugs and can be interpreted as a phenomenon where the joint effect of taking the two drugs together is considerably different from the expected effect in which drugs act independently of each other.\n",
        "\n",
        "The task at hand is to predict drug-drug interactions given information on already known drug-drug interactions. We want the model to rank true drug interactions higher than non-interacting drug pairs. Specifically, we rank each true drug interaction among a set of approximately 100,000 randomly-sampled negative drug interactions, and count the ratio of positive edges that are ranked at K-place or above (Hits@K)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1qfxdbvE3eR"
      },
      "source": [
        "## Code\n",
        "\n",
        "Now lets start coding our model. First we need to import PyTorch which is already installed in Google Colab and get its version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOmzDu06Ychs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee68nVpCFAPQ"
      },
      "source": [
        "After we get its version, we can install PyTorch Geometric (version needs to match PyTorch version printed above) and Open Graph Benchmark using pip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ovvky95NYiqL"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
        "!pip install -q torch-geometric\n",
        "!pip install ogb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7msNNwgFIi5"
      },
      "source": [
        "### Parameters\n",
        "\n",
        "First we will define the parameters that we will be using throughout the following code. These are parameters that we are using in our models and have been chosen to provide the best prediction accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vJtso7Tshku"
      },
      "outputs": [],
      "source": [
        "# Arguments\n",
        "INPUT_DIM = 512\n",
        "HIDDEN_DIM = 512\n",
        "OUTPUT_DIM = 256\n",
        "NUM_LAYERS = 3\n",
        "DROPOUT = 0.5\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 100\n",
        "TEST_TRAIN_SAMPLES = 100000\n",
        "BATCH_SIZE = 50000\n",
        "RUNS = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Dv5i1rxFYqv"
      },
      "source": [
        "### Importing data\n",
        "\n",
        "We will be importing data from `ogb.linkproppred` using `PygLinkPropPredDataset`. Later we will also use `Evaluator` from the same module, which will allow us to evaluate our predictions using the **hits@K** measure. In our case K will be 20.\n",
        "\n",
        "When we import the dataset, we transform it into a `SparseTensor` which allows us more efficient computing. Then we check which device is available, GPU or CPU, because we will be doing calculations on it. We recommend using GPU hardware accelerating, as it will provide much better performance.\n",
        "\n",
        "Our dataset contains only one graph, which has 4267 nodes. We use `get_edge_split` method on the database object, to get the train, valid and test edges. From the train set we only sample `TEST_TRAIN_SAMPLES` edges which we will actually be using during evaluation. Because our graph is a `SparseTensor`, we first create `edge_index` from it, from which we then sample the edges that are randomly selected using `torch.randperm` function.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpZhMQLeY-dw"
      },
      "outputs": [],
      "source": [
        "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "# Import database\n",
        "dataset = PygLinkPropPredDataset(name='ogbl-ddi', transform=T.ToSparseTensor())\n",
        "print('obl-ddi dataset has', len(dataset), 'graphs')\n",
        "\n",
        "# Check available device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device: {}'.format(device))\n",
        "\n",
        "# Get database graph\n",
        "graph = dataset[0].to(device)\n",
        "graph.num_nodes = 4267\n",
        "print(graph)\n",
        "\n",
        "# Get train, valid and test splits\n",
        "split_edge = dataset.get_edge_split()\n",
        "\n",
        "# Randomly sample edges for training accuracy\n",
        "row, col, _ = graph.adj_t.coo()\n",
        "edge_index = torch.stack([col, row], dim=0)\n",
        "\n",
        "split_edge['train_acc'] = {}\n",
        "\n",
        "idxs = torch.randperm(split_edge['train']['edge'].size(0))\n",
        "idxs = idxs[:TEST_TRAIN_SAMPLES]\n",
        "split_edge['train_acc']['edge'] = split_edge['train']['edge'][idxs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-5ZLqI2Hcjn"
      },
      "source": [
        "### GraphSAGE layer\n",
        "\n",
        "The first part of our model will be the GraphSAGE layer. This layer contains 2 `Linear` transformations. One is used on the current node embedding and the other on the aggregated embeddings of all the neighbours of the current node. We sum the results of these 2 transformations together and normalize them using `normalize` function from `torch.nn.functional`.\n",
        "\n",
        "The transformation objects are defined in the constructor and the main forward propagation in the `forward` method. The `message` method returns the message for the current node, which in this case is simply the embedding of the node in the current layer. The `aggregate` method simply aggregates all the embeddings of all the neighbours for every node and then calculates their mean value. This is then returned from the `propagate` method call.\n",
        "\n",
        "This layers can be written using the following mathematical notation:\n",
        "$$\n",
        "\\mathbf{h}_v^k = \\mathbf{W}_l \\cdot \\boldsymbol{h}_v^{k-1} + \\mathbf{W}_r \\cdot \\text{MEAN}(\\{\\mathbf{h}_u^{k-1}, \\forall u \\in \\mathcal N (v))\\})\n",
        "$$\n",
        "\n",
        "Here $\\mathbf{h}_v^k$ is the embedding of the node $v$ on the layer we are calculating, $\\mathbf{W}_l$ and $\\mathbf{W}_r$ are the `Linear` transforms. $\\text{MEAN}$ takes the embeddings of all the neighbours of $v$, $\\mathbf{h}_u^{k-1}$, on the previous layer and calculates their mean. This embeddings is then transformed and summed up with the transformed embedding of $v$ on the previous layer, $\\boldsymbol{h}_v^{k-1}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcVuvk_ao7LM"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "import torch_scatter\n",
        "\n",
        "class GraphSAGE(MessagePassing):\n",
        "  def __init__(self, input_dim, output_dim, bias=False):\n",
        "    super().__init__()\n",
        "    self.lin_l = Linear(input_dim, output_dim, bias=bias)\n",
        "    self.lin_r = Linear(input_dim, output_dim, bias=bias)\n",
        "\n",
        "    self.reset_parameters()\n",
        "  \n",
        "  def reset_parameters(self):\n",
        "    self.lin_l.reset_parameters()\n",
        "    self.lin_r.reset_parameters()\n",
        "  \n",
        "  def forward(self, x, edge_index, size=None):\n",
        "    out = self.lin_r(self.propagate(edge_index, x=(x, x), size=size))\n",
        "    out = self.lin_l(x) + out\n",
        "    out = F.normalize(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "  def message(self, x_j):\n",
        "    return x_j\n",
        "  \n",
        "  def aggregate(self, inputs, index, dim_size = None):\n",
        "    out = torch_scatter.scatter(inputs, index, self.node_dim, dim_size=dim_size, reduce='mean')\n",
        "    return out\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJVp0mhFK1Po"
      },
      "source": [
        "### GNN Stack\n",
        "\n",
        "Now we will stack multiple GraphSAGE layers together to create our Graph Neural Network that will predict node embeddings. We will be implementing the following pipeline:\n",
        "![GraphSAGE.png](data:image/png;base64,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)\n",
        "\n",
        "We do this by creating a class that extends `torch.nn.Module`. In the constructor we first create all the convolutional layers using `torch.nn.ModuleList`, where we are using GraphSAGE with `bias=True` for all of them. All the layers have the same parameters, except the first and last one, which have a different input or output dimension.\n",
        "\n",
        "In the forward propagation step that is implemented in method `forward` we feed node embedding into a GraphSAGE layer, followed by a ReLU activation function and dropout for every layer except the last one. We are using dropout to prevent overfitting to our data and we are only using it during training, since `training=self.training`. For the last layer we only use GraphSAGE.\n",
        "\n",
        "Here we also used an idea from the JK-Net (Jumping Knowledge Networks) paper. We save embedding at each layer into a list and feed the element wise maximum into the last GraphSAGE layer. This way we include skip connection to different layers and with max pooling we select the most informative layer for every embedding coordinate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kFq1FrqZ48m"
      },
      "outputs": [],
      "source": [
        "class GNN(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Dropout probability\n",
        "    self.dropout = dropout\n",
        "\n",
        "    self.convs = torch.nn.ModuleList()\n",
        "    # Add first layer\n",
        "    self.convs.append(GraphSAGE(input_dim, hidden_dim, True))\n",
        "    # Add hidden layers\n",
        "    for _ in range(num_layers - 2):\n",
        "      self.convs.append(GraphSAGE(hidden_dim, hidden_dim, True))\n",
        "    # Add last layers\n",
        "    self.convs.append(GraphSAGE(hidden_dim, output_dim, True))\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    for conv in self.convs:\n",
        "      conv.reset_parameters()\n",
        "\n",
        "  def forward(self, x, adj_t):\n",
        "    xs = []\n",
        "    for i in range(self.num_layers - 1):\n",
        "      x = self.convs[i](x, adj_t)\n",
        "      x = F.relu(x)\n",
        "      x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "      xs.append(x)\n",
        "    x = torch.stack(xs, dim=0)\n",
        "    x = torch.max(x, dim=0)[0] \n",
        "    x = self.convs[-1](x, adj_t)\n",
        "    \n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKXbwtIYNt1d"
      },
      "source": [
        "### Edge Predictor\n",
        "\n",
        "After getting node embeddings we need to predict new links in the graph. We do this by implementing Multi Layer Perceptron that returns the probability for edges composed from node pairs in `x_i` and `x_j` that are parameters passed into the `forward` method. Here we will implement the following pipeline:\n",
        "![MLP.png](data:image/png;base64,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)\n",
        "\n",
        "In the constructor we define layers of our MLP, which are simply `Linear` transformations with `bias=True` that we have already used.\n",
        "\n",
        "In the `forward` method we implement the forward pass. We are given 2 tensors, which represent embeddings of both ends of edges. To get probability for edges, we first multiply node embeddings element wise to get the first layer edge embeddings. We then feed these embeddings through our MLP layers in which we are also using ReLU activation function and dropout. On the last layer we only do a `Linear` transformation and use `sigmoid` function to produce valid probabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfXBYokv7nti"
      },
      "outputs": [],
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Dropout probability\n",
        "    self.dropout = dropout\n",
        "\n",
        "    self.convs = torch.nn.ModuleList()\n",
        "    # Add first layer\n",
        "    self.convs.append(Linear(input_dim, hidden_dim, True))\n",
        "    # Add hidden layers\n",
        "    for _ in range(num_layers - 2):\n",
        "      self.convs.append(Linear(hidden_dim, hidden_dim, True))\n",
        "    # Add last layers\n",
        "    self.convs.append(Linear(hidden_dim, output_dim, True))\n",
        "\n",
        "    self.reset_parameters()\n",
        "  \n",
        "  def reset_parameters(self):\n",
        "    for conv in self.convs:\n",
        "      conv.reset_parameters()\n",
        "\n",
        "  def forward(self, x_i, x_j):\n",
        "    x = x_i * x_j\n",
        "\n",
        "    for i in range(self.num_layers - 1):\n",
        "      x = self.convs[i](x)\n",
        "      x = F.relu(x)\n",
        "      x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "    x = self.convs[-1](x)\n",
        "\n",
        "    # Return number from 0 to 1 for every edge\n",
        "    return torch.sigmoid(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhTdosjESZQV"
      },
      "source": [
        "### Test function\n",
        "\n",
        "Before our test function we need to use `no_grad` decorator to turn off gradient computation as it is not needed during testing. Then we switch to **evaluation mode** with a call of `eval` on our models. This acts as a switch for layers that behave differently during training and evaluation(i.e. dropout).\n",
        "\n",
        "Next we need to get node embeddings, which we do using `model` which is our `GNN` object. We feed it node embeddings, `x.weight` and graph data `graph.adj_t`. We also set `K` parameter to 20 for our evaluator.\n",
        "\n",
        "To be able to compute accuracy we need edge predictions for different subsets(valid, test and train). Valid and test are computed exactly the same with the exception of set names. We take into consideration positive and negative edges.\n",
        "From `split_edge` we simply take the edges for which we want to calculate embeddings and feed their nodes into edge prediction model `edge_model`. The result is a 1D tensor of probabilities that we put into `eval` function of our evaluator which is provided by OGB. Because we do not have training negative edges, we use the ones from valid split to obtain a train accuracy measure.\n",
        "\n",
        "At the end we just return accuracy measure hits@20 that are calculated by `evaluator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt9XvlKFGKf2"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(evaluator, model, edge_model, split_edge, x, graph):\n",
        "  model.eval()\n",
        "  edge_model.eval()\n",
        "\n",
        "  # Forward propagation to obtain node embeddings\n",
        "  embeddings = model(x.weight, graph.adj_t)\n",
        "\n",
        "  evaluator.K = 20;\n",
        "\n",
        "  # Get edge predictions for valid edges\n",
        "  positive_valid_edges = split_edge['valid']['edge'].t().to(device)\n",
        "  predictions_valid_pos = edge_model(embeddings[positive_valid_edges[0]],\n",
        "                                 embeddings[positive_valid_edges[1]])\n",
        "  negative_valid_edges = split_edge['valid']['edge_neg'].t().to(device)\n",
        "  predictions_valid_neg = edge_model(embeddings[negative_valid_edges[0]],\n",
        "                                 embeddings[negative_valid_edges[1]])\n",
        "\n",
        "  valid_hits = evaluator.eval({\n",
        "    'y_pred_pos': predictions_valid_pos.flatten(),\n",
        "    'y_pred_neg': predictions_valid_neg.flatten(),\n",
        "  })['hits@20']\n",
        "\n",
        "  # Get edge predictions for test edges\n",
        "  positive_test_edges = split_edge['test']['edge'].t().to(device)\n",
        "  predictions_test_pos = edge_model(embeddings[positive_test_edges[0]],\n",
        "                                 embeddings[positive_test_edges[1]])\n",
        "  negative_test_edges = split_edge['test']['edge_neg'].t().to(device)\n",
        "  predictions_test_neg = edge_model(embeddings[negative_test_edges[0]],\n",
        "                                 embeddings[negative_test_edges[1]])\n",
        "\n",
        "  test_hits = evaluator.eval({\n",
        "    'y_pred_pos': predictions_test_pos.flatten(),\n",
        "    'y_pred_neg': predictions_test_neg.flatten(),\n",
        "  })['hits@20']\n",
        "\n",
        "  # Get edge predictions for a subset of train edges\n",
        "  positive_train_edges = split_edge['train_acc']['edge'].t().to(device)\n",
        "  predictions_train_pos = edge_model(embeddings[positive_train_edges[0]],\n",
        "                                 embeddings[positive_train_edges[1]])\n",
        "\n",
        "  train_hits = evaluator.eval({\n",
        "    'y_pred_pos': predictions_train_pos.flatten(),\n",
        "    'y_pred_neg': predictions_valid_neg.flatten(),\n",
        "  })['hits@20']\n",
        "\n",
        "  return train_hits, valid_hits, test_hits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9fs41uxSak2"
      },
      "source": [
        "### Train function\n",
        "\n",
        "Our `train` function will build all the models and train them using given parameters.\n",
        "\n",
        "We first get positive train edges from graph splits which we will use in training. For negative sampling we need an edge index, which we obtain from our graph data.\n",
        "\n",
        "Then we create our models. The first one, `model`, will generate node embeddings, and `edge_model` will create edge predictions. We need to make sure both of them are on the device we are currently using, which is stored in `device` variable. Because we want edge predictor to generate probabilities, we make sure to make its output dimension 1.\n",
        "\n",
        "As this graph does not have any node features, we will use `torch.nn.Embedding` class to create learnable features. As with the models, we move them to the appropriate device.\n",
        "\n",
        "Evaluator is provided by Open Graph Benchmark and we create the specific one for our database using `Evaluator(name='ogbl-ddi')`. For the optimizer we will be using Adam optimizer. It will optimize parameters for both of our models, as well as node features which we will learn.\n",
        "\n",
        "Now we run the training for a specific number of epochs. For every epoch we will calculate the loss which we will print at the end of it. First we make sure our models are in train mode using `train` method call. Then we create a loader for our graph, which will create mini-batches for us.\n",
        "\n",
        "For every mini-batch we will calculate the loss, add it to the total current epoch loss and optimize parameters. First we zero out our optimizer. Then we do a forward pass on our `model` and get positive edges for the current mini-batch using `perm`, which is a tensor containing indexes of edges for the current mini-batch. To get negative edges we use `negative_sampling` function from PyTorch Geometric.\n",
        "\n",
        "After obtaining node embeddings, positive and negative edges, we create edge probabilites for our selected edges. We want probabilities to be high for positive and low for negative edges. To achieve this we will be minimizing Binary Cross Entropy:\n",
        "$$\n",
        "\\mathcal L = - \\frac{1}{N} \\sum \\left[ y_i \\cdot \\log(\\hat y_i) + (1 - y_i) \\cdot \\log(1 - \\hat y_i) \\right] ,\n",
        "$$\n",
        "where $\\hat y_i$ is $i$-th edge predicted probability and $y_i$ is 1 for positive edges and 0 for negative ones. \n",
        "\n",
        "At the end of epoch, we divide the total loss by number of edges, to get loss per edge and call `test` function to obtain train, valid and test accuracies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhAbfzG-w_4r"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import DataLoader\n",
        "from torch_sparse import SparseTensor\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "def train(\n",
        "    graph, splits, epochs, batch_size, input_dim, hidden_dim, output_dim,\n",
        "    num_layers, dropout, learning_rate, device\n",
        "  ):\n",
        "\n",
        "  positive_train_edges = splits['train']['edge'].to(device)\n",
        "  row, col, _ = graph.adj_t.coo()\n",
        "  edge_index = torch.stack([col, row], dim=0)\n",
        "\n",
        "  # Create model\n",
        "  model = GNN(input_dim, hidden_dim, output_dim, num_layers, dropout).to(device)\n",
        "  edge_model = MLP(output_dim, output_dim // 2, 1, num_layers, dropout).to(device)\n",
        "\n",
        "  # Create learnable features\n",
        "  x = torch.nn.Embedding(graph.num_nodes, input_dim).to(device)\n",
        "\n",
        "  evaluator = Evaluator(name='ogbl-ddi')\n",
        "\n",
        "  # Create optimizer\n",
        "  adam = torch.optim.Adam(\n",
        "      list(model.parameters()) + list(x.parameters()) + list(edge_model.parameters()),\n",
        "      lr=learning_rate)\n",
        "\n",
        "  for epoch in range(1, 1 + epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    edge_model.train()\n",
        "\n",
        "    # Create loader for mini batching\n",
        "    loader = DataLoader(range(positive_train_edges.size(0)), batch_size, shuffle=True)\n",
        "\n",
        "    # Process every batch\n",
        "    for perm in loader:\n",
        "      adam.zero_grad()\n",
        "\n",
        "      # Forward pass\n",
        "      embeddings = model(x.weight, graph.adj_t)\n",
        "\n",
        "      # Get batch positive and negative edges\n",
        "      batch_edges = positive_train_edges[perm].t()\n",
        "      neg_edges = negative_sampling(edge_index, num_nodes=graph.num_nodes,\n",
        "                                    num_neg_samples=perm.size(0), method='dense')\n",
        "\n",
        "      # Predict edges using MLP\n",
        "      batch_predictions = edge_model(embeddings[batch_edges[0]], embeddings[batch_edges[1]])\n",
        "      neg_predictions = edge_model(embeddings[neg_edges[0]], embeddings[neg_edges[1]])\n",
        "\n",
        "      # Calculate loss (BCE)\n",
        "      pos_loss = -torch.log(batch_predictions + 1e-15).mean() \n",
        "      neg_loss = -torch.log(1 - neg_predictions + 1e-15).mean() \n",
        "\n",
        "      loss = pos_loss + neg_loss\n",
        "      total_loss += batch_edges.size()[1] * loss\n",
        "\n",
        "      # Backpropagate\n",
        "      loss.backward()\n",
        "      adam.step()\n",
        "\n",
        "    total_loss /= positive_train_edges.size(0) \n",
        "\n",
        "    train_hits, valid_hits, test_hits = test(evaluator, model, edge_model, splits, x, graph)\n",
        "    print(f'Epoch: {epoch}, Loss: {total_loss:.3f}, '\n",
        "           f'Train hits@20: {100 * train_hits:.2f}%, '\n",
        "           f'Valid hits@20: {100 * valid_hits:.2f}%, '\n",
        "           f'Test hits@20: {100 * test_hits:.2f}%')\n",
        "    \n",
        "  return valid_hits, test_hits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IcUVSvtSeU0"
      },
      "source": [
        "### Training\n",
        "\n",
        "Now we run our model training using the parameters we have defined at the beggining. We run the training multiple times and save the best model results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDlC1XLEsVVi"
      },
      "outputs": [],
      "source": [
        "best_valid, best_test = 0, 0\n",
        "\n",
        "for run in range(1, RUNS + 1):\n",
        "  print(f'Run: {run}')\n",
        "  curr_valid, curr_test = train(graph, split_edge, EPOCHS, BATCH_SIZE, INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
        "      NUM_LAYERS, DROPOUT, LEARNING_RATE, device)\n",
        "  if curr_test > best_test:\n",
        "    best_valid, best_test = curr_valid, curr_test\n",
        "  print('-' * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIMRxfIzSiYo"
      },
      "source": [
        "## Best results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3wTnkXRZy1a"
      },
      "outputs": [],
      "source": [
        "print(f'Best model valid accuracy: {100 * best_valid:.2f}%')\n",
        "print(f'Best model test accuracy: {100 * best_test:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}